<!DOCTYPE html>
<html lang="en">

<head>
    <title>Bavanya</title>
</head>

<body>
    <h2>I am interested in:</h2>
    <ul>
        <li>Designing methodologies for Spatio-temporal visual analysis.</li>
        <li>Graphical models, especially for Spatio-temporal data.</li>
        <li>Designing computational models.</li>
        <li>Quantifying confidence and uncertainity (eg: using Bayesian inference methods, especially for time series data) in predictions.</li>
        <li>Designing deep probabilistic models and inference algorithms.</li>
        <li><a href="https://ermongroup.github.io/cs228-notes/">Probabilistic graphical models</a></li>
        <li>Spatio-temporal forecasting and mining, data-driven and knowledge-guided.</li>
        <li>Designing methodologies for graph analysis and mining, especially <a href="https://blog.twitter.com/engineering/en_us/topics/insights/2021/temporal-graph-networks">dynamic</a> and Spatio-temporal graphs.</li>
        <li>Statistical and probabilistic methods for Spatio-temporal data.</li>
        <li>Domain adaptive and few-shot attention-based models for forecasting problems.</li>
        <li>GIS</li>
        <li>Mapping and Spatial Analysis techniques.</li>
        <li>Using Gunrock library on Spatio-temporal graphs.</li>
        <li>GNNs.</li>
        <li>Domain adaptive and few-shot attention-based models for forecasting problems.</li>
    </ul>

    <h2>Some Interesting Concepts (<a href="https://github.com/bavanya/My_Ideas_and_Notes/blob/main/statistics_probability_machine-learning.pdf">My notes present here</a>):</h2>
    <ul>
        <li><a href="https://towardsdatascience.com/probability-concepts-explained-maximum-likelihood-estimation-c7b4342fdbb1">Maximum Likelihood Estimation</a></li>
        <li><a href="https://towardsdatascience.com/probability-concepts-explained-bayesian-inference-for-parameter-estimation-90e8930e5348">Bayesian inference for parameter estimation</a>, <a href="https://arxiv.org/abs/1601.00670">Variational inference</a>.</li>
        <li><a href="https://ned.ipac.caltech.edu/level5/March02/Silverman/Silver1.html">Density Estimation</a>, <a href="https://www.pnas.org/content/118/15/e2101344118">density estimation using deep generative networks</a>, <a href="https://igppweb.ucsd.edu/~cathy/Classes/SIO223A/sio223a.chap9.pdf">non-parametric density estimation</a>.</li>
        <li>Active Learning, Sequential Learning and Parametric Unsupervised Learning.</li>
        <li>Different types of data and <a href="http://people.stern.nyu.edu/adamodar/New_Home_Page/StatFile/statdistns.htm">different statistical distributions</a>.</li>
        <li><a href="https://www.ics.uci.edu/~dechter/courses/ics-276/spring-19/">Probabilistic and Deterministic Graphical Models</a>, <a href="https://blog.katastros.com/a?ID=00750-b8a98828-73d9-4a52-9d19-24ea16feb33b">Probabilistic Graphical Models</a></li>
        <li><a href="https://towardsdatascience.com/what-is-operations-research-1541fb6f4963">Operations Research</a></li>
        <li><a href="https://statswithr.github.io/book/the-basics-of-bayesian-statistics.html">Bayesian Statistics</a>, Bayesian networks.</li>
        <li>Monte Carlo methods (<a href="http://compphysics.github.io/ComputationalPhysics/doc/pub/mcint/html/mcint.html">Computational Physics</a>), <a href="https://web.stanford.edu/~jurafsky/slp3/A.pdf">Hidden Markov Model</a>, <a href="https://www.ias.ac.in/article/fulltext/reso/019/08/0713-0739">Monte Carlo sampling</a> and <a href="https://arxiv.org/pdf/1909.12313.pdf">Monte Carlo Markov Chain methods</a>.</li>
        <li>Quantifying uncertainity in statistical, machine learning and deep learning models and obtaining prediction intervals.</li>
        <li>Optimization algorithms, <a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0122827">swarm optimization algorithms</a>.</li>
        <li>Topological data analysis.</li>
        <li>Missing data imputation methods, especially for temporal data.</li>
        <li>Mixture modelling.</li>
        <li>Survival analysis.</li>
        <li>Markov chains and stochastic processes.</li>
        <li>Spine-based models.</li>
        <li>Adding penalties to models, eg: elastic net, lasso, lars.</li>
        <li>Stochastic process.</li>
        <li>Functional programming and Logical programming.</li>
        <li>Convex optimization.</li>
        <li><a href="https://nptel.ac.in/courses/111/105/111105043/">Statistical inference</a></li>
        <li>Practical applications of non-parametric statistics.</li>
        <li>Frequentist approach to statistics.</li>
        <li>Class imbalance problem.</li>
        <li><a href="https://statisticsbyjim.com/hypothesis-testing/confidence-prediction-tolerance-intervals/">Confidence interval vs prediction interval vs tolerance interval</a>.</li>
        <li><a href="https://towardsdatascience.com/predicting-probability-distributions-using-neural-networks-abef7db10eac">Predicting probability distributions using neural networks</a></li>
        <li><a href="http://edwardlib.org/tutorials/bayesian-neural-network">Bayesian neural network</a>, mixed density network.</li>
        <li>Hypothesis testing.</li>
        <li><a href="https://neptune.ai/blog/understanding-few-shot-learning-in-computer-vision">Few-shot learning</a>.</li>
        <li><a href="https://towardsdatascience.com/self-supervised-learning-methods-for-computer-vision-c25ec10a91bd">Self-supervised learning</a>, Contrastive learning and restricted boltzmann machines.</li>
        <li>Representation learning.</li>
        <li>Generative models.</li>
        <li>Energy based models, deep belief networks, factor graphs, radial basis function neural networks.</li>
        <li><a href="https://towardsdatascience.com/understanding-gaussian-process-the-socratic-way-ba02369d804">Gaussian process</a>, <a href="https://towardsdatascience.com/an-intuitive-guide-to-gaussian-processes-ec2f0b45c71d">another post</a> and scalable gaussian process.</li>
        <li>Euclidean and Non-Euclidean domains.</li>
        <li>Graph representation learning, Graph kernels, random-walk methods, Graph neural networks.</li>
        <li><a href="https://viso.ai/deep-learning/adversarial-machine-learning/">Adversial machine learning</a>, Deep Reinforcement Learning.</li>
        <li><a href="https://en.wikipedia.org/wiki/Kernel_(statistics">Kernel in statistics</a>#Kernel_functions_in_common_use), kernel density estimation, kernel regression, multivariate kernel density estimation.</li>
        <li>Multi dimensional scaling, <a href="https://towardsdatascience.com/11-dimensionality-reduction-techniques-you-should-know-in-2021-dcb9500d388b">non-linear dimensionality reduction</a>.</li>
        <li><a href="https://ieeexplore.ieee.org/document/9555949">Bayesian graph neural networks</a>.</li>
    </ul>
    

    <h2>Some papers I found interesting:</h2>
    <ul>
        <li><a href="https://arxiv.org/abs/1506.05163">Deep Convolutional Networks on Graph-Structured Data.</a></li>
        <li>Cyclical Stochastic Gradient MCMC for Bayesian Deep Learning.</li>
    </ul>

    <h2>Cool libraries that I found:</h2>
    <ul>
        <li><a href="http://edwardlib.org/tutorials/bayesian-neural-network">Edward</a></li>
    </ul>

    <h2>Other interesting links:</h2>
    <ul>
        <li><a href="https://www.kdnuggets.com/2019/05/probability-mass-density-functions.html">Series by Hadrien Jean on the Deep Learning Book by Ian Goodfellow.</a></li>    
        <li><a href="https://bloomberg.github.io/foml/#about">Bloomberg's "Foundations of Machine Learning," course.</a></li>    
        <li><a href="https://medium.com/mlearning-ai/monte-carlo-simulation-in-machine-learning-using-rbf-sampler-fdf9d35b3c18">Monte Carlo simulation in machine learning.</a></li>    
    </ul>

</body>
</html>