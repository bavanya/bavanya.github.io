<!DOCTYPE html>
<html lang="en">

<head>
    <title>Bavanya</title>
</head>

<body>
    <h2>I am interested in:</h2>
    <ul>
        <li>Designing methodologies for Spatio-temporal visual analysis.</li>
        <li>Graphical models, especially for Spatio-temporal data.</li>
        <li>Designing computational models.</li>
        <li>Quantifying confidence and uncertainity (eg: using Bayesian inference methods, especially for time series data) in predictions.</li>
        <li>Designing deep probabilistic models and inference algorithms.</li>
        <li><a href="https://ermongroup.github.io/cs228-notes/">Probabilistic graphical models</a></li>
        <li>Spatio-temporal forecasting and mining, data-driven and knowledge-guided.</li>
        <li>Designing methodologies for graph analysis and mining, especially <a href="https://blog.twitter.com/engineering/en_us/topics/insights/2021/temporal-graph-networks">dynamic</a> and Spatio-temporal graphs.</li>
        <li>Statistical and probabilistic methods for Spatio-temporal data.</li>
        <li>Domain adaptive and few-shot attention-based models for forecasting problems.</li>
        <li>GIS</li>
        <li>Mapping and Spatial Analysis techniques.</li>
        <li>Using Gunrock library on Spatio-temporal graphs.</li>
        <li>GNNs.</li>
        <li>Domain adaptive and few-shot attention-based models for forecasting problems.</li>
    </ul>

**Some Interesting Concepts ([My notes present here](https://github.com/bavanya/My_Ideas_and_Notes/blob/main/statistics_probability_machine-learning.pdf)):**
1. [Maximum Likelihood Estimation](https://towardsdatascience.com/probability-concepts-explained-maximum-likelihood-estimation-c7b4342fdbb1)
2. [Bayesian inference for parameter estimation](https://towardsdatascience.com/probability-concepts-explained-bayesian-inference-for-parameter-estimation-90e8930e5348), [Variational inference](https://arxiv.org/abs/1601.00670).
3. [Density Estimation](https://ned.ipac.caltech.edu/level5/March02/Silverman/Silver1.html), [density estimation using deep generative networks](https://www.pnas.org/content/118/15/e2101344118), [non-parametric density estimation](https://igppweb.ucsd.edu/~cathy/Classes/SIO223A/sio223a.chap9.pdf).
4. Active Learning, Sequential Learning and Parametric Unsupervised Learning.
5. Different types of data and [different statistical distributions](http://people.stern.nyu.edu/adamodar/New_Home_Page/StatFile/statdistns.htm).
6. [Probabilistic and Deterministic Graphical Models](https://www.ics.uci.edu/~dechter/courses/ics-276/spring-19/), [Probabilistic Graphical Models](https://blog.katastros.com/a?ID=00750-b8a98828-73d9-4a52-9d19-24ea16feb33b)
7. [Operations Research](https://towardsdatascience.com/what-is-operations-research-1541fb6f4963)
8. [Bayesian Statistics](https://statswithr.github.io/book/the-basics-of-bayesian-statistics.html), Bayesian networks.
9. Monte Carlo methods ([Computational Physics](http://compphysics.github.io/ComputationalPhysics/doc/pub/mcint/html/mcint.html)), [Hidden Markov Model](https://web.stanford.edu/~jurafsky/slp3/A.pdf), [Monte Carlo sampling](https://www.ias.ac.in/article/fulltext/reso/019/08/0713-0739) and [Monte Carlo Markov Chain methods](https://arxiv.org/pdf/1909.12313.pdf).
10. Quantifying uncertainity in statistical, machine learning and deep learning models and obtaining prediction intervals.
11. Optimization algorithms, [swarm optimization algorithms](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0122827).
12. Topological data analysis.
13. Missing data imputation methods, especially for temporal data.
14. Mixture modelling.
15. Survival analysis.
16. Markov chains and stochastic processes.
17. Spine-based models.
18. Adding penalties to models, eg: elastic net, lasso, lars.
19. Stochastic process.
20. Functional programming and Logical programming.
21. Convex optimization.
22. [Statistical inference](https://nptel.ac.in/courses/111/105/111105043/)
23. Practical applications of non-parametric statistics.
24. Frequentist approach to statistics.
25. Class imbalance problem.
26. [Confidence interval vs prediction interval vs tolerance interval](https://statisticsbyjim.com/hypothesis-testing/confidence-prediction-tolerance-intervals/).
27. [Predicting probability distributions using neural networks](https://towardsdatascience.com/predicting-probability-distributions-using-neural-networks-abef7db10eac)
28. [Bayesian neural network](http://edwardlib.org/tutorials/bayesian-neural-network), mixed density network.
29. Hypothesis testing.
30. [Few-shot learning](https://neptune.ai/blog/understanding-few-shot-learning-in-computer-vision).
31. [Self-supervised learning](https://towardsdatascience.com/self-supervised-learning-methods-for-computer-vision-c25ec10a91bd), Contrastive learning and restricted boltzmann machines.
32. Representation learning.
33. Generative models.
34. Energy based models, deep belief networks, factor graphs, radial basis function neural networks.
35. [Gaussian process](https://towardsdatascience.com/understanding-gaussian-process-the-socratic-way-ba02369d804), [another post](https://towardsdatascience.com/an-intuitive-guide-to-gaussian-processes-ec2f0b45c71d) and scalable gaussian process.
36. Euclidean and Non-Euclidean domains.
37. Graph representation learning, Graph kernels, random-walk methods, Graph neural networks.
38. [Adversial machine learning](https://viso.ai/deep-learning/adversarial-machine-learning/), Deep Reinforcement Learning.
39. [Kernel in statistics](https://en.wikipedia.org/wiki/Kernel_(statistics)#Kernel_functions_in_common_use), kernel density estimation, kernel regression, multivariate kernel density estimation.
40. Multi dimensional scaling, [non-linear dimensionality reduction](https://towardsdatascience.com/11-dimensionality-reduction-techniques-you-should-know-in-2021-dcb9500d388b).
41. [Bayesian graph neural networks](https://ieeexplore.ieee.org/document/9555949).

<h2>Some papers I found interesting:</h2>
<ul>
    <li><a href="https://arxiv.org/abs/1506.05163">Deep Convolutional Networks on Graph-Structured Data.</a></li>
    <li>Cyclical Stochastic Gradient MCMC for Bayesian Deep Learning.</li>
</ul>

<h2>Cool libraries that I found:</h2>
<ul>
    <li><a href="http://edwardlib.org/tutorials/bayesian-neural-network">Edward</a></li>
</ul>

<h2>Other interesting links:</h2>
<ul>
    <li><a href="https://www.kdnuggets.com/2019/05/probability-mass-density-functions.html">Series by Hadrien Jean on the Deep Learning Book by Ian Goodfellow.</a></li>    
    <li><a href="https://bloomberg.github.io/foml/#about">Bloomberg's "Foundations of Machine Learning," course.</a></li>    
    <li><a href="https://medium.com/mlearning-ai/monte-carlo-simulation-in-machine-learning-using-rbf-sampler-fdf9d35b3c18">Monte Carlo simulation in machine learning.</a></li>    
</ul>

</body>
</html>